# File: agents/training/mps_optimization.py  
# CRITICAL FIX: Apple Silicon MPS Mixed Precision Optimization

import torch
import torch.nn as nn
from torch.cuda.amp import GradScaler, autocast
import time
import numpy as np
from typing import Dict, Optional, Tuple, Any
import logging
from contextlib import contextmanager

class MPSOptimizedTrainer:
    """Enhanced trainer with Apple Silicon MPS optimizations"""
    
    def __init__(self, 
                 network: nn.Module,
                 device: torch.device,
                 use_mixed_precision: bool = True,
                 use_memory_optimization: bool = True):
        
        self.network = network
        self.device = device
        self.use_mixed_precision = use_mixed_precision
        self.use_memory_optimization = use_memory_optimization
        
        # Initialize mixed precision training components
        if use_mixed_precision and device.type == 'mps':
            # MPS-specific optimizations
            self.scaler = GradScaler('mps')  # Use MPS backend
            self.autocast_dtype = torch.float16
        elif use_mixed_precision and device.type == 'cuda':
            self.scaler = GradScaler('cuda')
            self.autocast_dtype = torch.float16
        else:
            self.scaler = None
            self.autocast_dtype = torch.float32
        
        # MPS-specific optimizations
        if device.type == 'mps':
            self._configure_mps_optimizations()
        
        self.logger = logging.getLogger(__name__)
        self.logger.info(f"ğŸ”¥ MPS Optimized Trainer initialized on {device}")
        self.logger.info(f"   Mixed Precision: {use_mixed_precision}")
        self.logger.info(f"   Memory Optimization: {use_memory_optimization}")
    
    def _configure_mps_optimizations(self):
        """Configure MPS-specific optimizations"""
        
        # Enable memory-efficient attention if available
        try:
            torch.backends.mps.enable_flash_attention_if_available()
            self.logger.info("âœ… Flash attention enabled")
        except:
            self.logger.info("âš ï¸ Flash attention not available")
        
        # Set optimal memory settings
        if hasattr(torch.backends.mps, 'set_memory_fraction'):
            torch.backends.mps.set_memory_fraction(0.8)  # Use 80% of GPU memory
        
        # Enable optimal tensor operations
        torch.backends.mps.enable_fallback(True)  # Enable CPU fallback for unsupported ops
    
    @contextmanager
    def autocast_context(self):
        """Context manager for mixed precision operations"""
        if self.use_mixed_precision and self.device.type in ['mps', 'cuda']:
            if self.device.type == 'mps':
                # MPS autocast
                with torch.autocast(device_type='mps', dtype=self.autocast_dtype):
                    yield
            else:
                # CUDA autocast
                with torch.autocast(device_type='cuda', dtype=self.autocast_dtype):
                    yield
        else:
            # No autocast
            yield
    
    def optimized_forward_pass(self, 
                              observations: torch.Tensor,
                              agent_states: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """Forward pass with MPS optimizations"""
        
        # Ensure tensors are in optimal format for MPS
        if self.device.type == 'mps':
            observations = observations.contiguous()
            agent_states = agent_states.contiguous()
        
        # Mixed precision forward pass
        with self.autocast_context():
            action_logits, state_values = self.network(observations, agent_states)
        
        return action_logits, state_values
    
    def optimized_backward_pass(self, 
                               loss: torch.Tensor,
                               optimizer: torch.optim.Optimizer) -> Dict[str, float]:
        """Backward pass with MPS optimizations and gradient scaling"""
        
        stats = {}
        
        # Scale loss for mixed precision
        if self.scaler is not None:
            scaled_loss = self.scaler.scale(loss)
            scaled_loss.backward()
            
            # Unscale gradients
            self.scaler.unscale_(optimizer)
            
            # Gradient clipping
            grad_norm = torch.nn.utils.clip_grad_norm_(self.network.parameters(), max_norm=0.5)
            
            # Optimizer step
            self.scaler.step(optimizer)
            self.scaler.update()
            
            stats['grad_norm'] = grad_norm.item()
            stats['loss_scale'] = self.scaler.get_scale()
        else:
            # Standard training
            loss.backward()
            
            grad_norm = torch.nn.utils.clip_grad_norm_(self.network.parameters(), max_norm=0.5)
            optimizer.step()
            
            stats['grad_norm'] = grad_norm.item()
            stats['loss_scale'] = 1.0
        
        return stats
    
    def benchmark_performance(self, 
                            batch_size: int = 32,
                            num_iterations: int = 100) -> Dict[str, float]:
        """Benchmark training performance with optimizations"""
        
        self.logger.info(f"ğŸƒâ€â™‚ï¸ Benchmarking MPS performance: {num_iterations} iterations")
        
        # Create dummy data
        observations = torch.randn(batch_size, 5, 15, 15, device=self.device)
        agent_states = torch.randn(batch_size, 8, device=self.device)
        
        # Create optimizer
        optimizer = torch.optim.Adam(self.network.parameters(), lr=1e-3)
        
        # Warmup (MPS needs warmup for optimal performance)
        for _ in range(10):
            with self.autocast_context():
                action_logits, state_values = self.network(observations, agent_states)
                loss = action_logits.mean() + state_values.mean()
            loss.backward()
            optimizer.step()
            optimizer.zero_grad()
        
        # Synchronize before timing
        if self.device.type == 'mps':
            torch.mps.synchronize()
        elif self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        # Benchmark training loop
        start_time = time.perf_counter()
        
        total_samples = 0
        
        for iteration in range(num_iterations):
            optimizer.zero_grad()
            
            # Forward pass
            with self.autocast_context():
                action_logits, state_values = self.network(observations, agent_states)
                
                # Dummy loss computation
                policy_loss = -action_logits.mean()
                value_loss = state_values.pow(2).mean()
                total_loss = policy_loss + value_loss
            
            # Backward pass with optimization
            backward_stats = self.optimized_backward_pass(total_loss, optimizer)
            
            total_samples += batch_size
        
        # Synchronize and measure time
        if self.device.type == 'mps':
            torch.mps.synchronize()
        elif self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        end_time = time.perf_counter()
        
        # Calculate metrics
        total_time = end_time - start_time
        samples_per_sec = total_samples / total_time
        iterations_per_sec = num_iterations / total_time
        
        results = {
            'samples_per_sec': samples_per_sec,
            'iterations_per_sec': iterations_per_sec,
            'total_time': total_time,
            'avg_iteration_time': total_time / num_iterations,
            'device': str(self.device),
            'mixed_precision': self.use_mixed_precision,
            'batch_size': batch_size
        }
        
        self.logger.info(f"ğŸ“Š Performance Results:")
        self.logger.info(f"   Samples/sec: {samples_per_sec:.1f}")
        self.logger.info(f"   Iterations/sec: {iterations_per_sec:.1f}")
        self.logger.info(f"   Avg iteration time: {results['avg_iteration_time']*1000:.2f}ms")
        
        return results

def benchmark_mixed_precision_improvement():
    """Compare FP32 vs FP16 performance on MPS"""
    
    print("âš¡ Benchmarking Mixed Precision Improvement...")
    
    try:
        # Import network factory
        if not IMPORTS_AVAILABLE:
            print("âš ï¸ Cannot run benchmark - imports not available")
            return {'status': 'skipped'}
        
        from agents.networks.network_factory import create_standard_network
        
        device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
        print(f"ğŸ”¥ Using device: {device}")
        
        # Test FP32 performance
        network_fp32 = create_standard_network()
        trainer_fp32 = MPSOptimizedTrainer(
            network=network_fp32,
            device=device,
            use_mixed_precision=False
        )
        
        fp32_results = trainer_fp32.benchmark_performance(batch_size=32, num_iterations=50)
        
        # Test FP16 performance  
        network_fp16 = create_standard_network()
        trainer_fp16 = MPSOptimizedTrainer(
            network=network_fp16,
            device=device,
            use_mixed_precision=True
        )
        
        fp16_results = trainer_fp16.benchmark_performance(batch_size=32, num_iterations=50)
        
        # Calculate improvement
        speedup = fp16_results['samples_per_sec'] / fp32_results['samples_per_sec']
        
        print(f"\nğŸ“ˆ MIXED PRECISION RESULTS:")
        print(f"   FP32: {fp32_results['samples_per_sec']:.1f} samples/sec")
        print(f"   FP16: {fp16_results['samples_per_sec']:.1f} samples/sec")
        print(f"   Speedup: {speedup:.2f}x")
        
        success = speedup > 1.2  # Target at least 20% improvement
        
        return {
            'status': 'success',
            'fp32_performance': fp32_results['samples_per_sec'],
            'fp16_performance': fp16_results['samples_per_sec'],
            'speedup': speedup,
            'target_achieved': success,
            'recommendation': 'Enable mixed precision' if success else 'Investigate MPS optimization'
        }
        
    except Exception as e:
        print(f"âŒ Mixed precision benchmark failed: {e}")
        return {'status': 'failed', 'error': str(e)}

# Comprehensive optimization test
def run_performance_optimization_validation():
    """Run complete performance optimization validation"""
    
    print("ğŸš€ PERFORMANCE OPTIMIZATION VALIDATION")
    print("=" * 50)
    
    results = {}
    
    # Test 1: RIL Framework Fix
    print("\n1. ğŸ§  Testing RIL Framework Fix...")
    results['ril_fix'] = test_ril_framework_fixed()
    
    # Test 2: Mixed Precision Optimization
    print("\n2. âš¡ Testing Mixed Precision Optimization...")
    results['mixed_precision'] = benchmark_mixed_precision_improvement()
    
    # Test 3: Integration Test
    print("\n3. ğŸ”— Testing RIL + PPO Integration...")
    results['integration'] = test_integration_with_ppo()
    
    # Performance Analysis
    print("\nğŸ“Š OPTIMIZATION ANALYSIS:")
    
    overall_success = True
    improvements = []
    
    # Analyze RIL fix
    if results['ril_fix']['status'] == 'success':
        print("âœ… RIL Framework: OPERATIONAL")
        improvements.append("Meta-learning framework functional")
    else:
        print("âŒ RIL Framework: NEEDS WORK")
        overall_success = False
    
    # Analyze mixed precision
    if results['mixed_precision']['status'] == 'success':
        speedup = results['mixed_precision']['speedup']
        if speedup > 1.5:
            print(f"âœ… Mixed Precision: EXCELLENT ({speedup:.2f}x speedup)")
            improvements.append(f"Achieved {speedup:.2f}x mixed precision improvement")
        elif speedup > 1.2:
            print(f"âœ… Mixed Precision: GOOD ({speedup:.2f}x speedup)")
            improvements.append(f"Achieved {speedup:.2f}x mixed precision improvement")
        else:
            print(f"âš ï¸ Mixed Precision: PARTIAL ({speedup:.2f}x speedup)")
            improvements.append("Mixed precision shows limited improvement")
    else:
        print("âŒ Mixed Precision: FAILED")
        overall_success = False
    
    # Analyze integration
    if results['integration']['status'] == 'success':
        if results['integration']['adaptation_successful']:
            print("âœ… RIL Integration: FUNCTIONAL")
            improvements.append("Meta-learning adaptation validated")
        else:
            print("âš ï¸ RIL Integration: PARTIAL")
            improvements.append("Integration working but adaptation needs tuning")
    else:
        print("âŒ RIL Integration: FAILED")
    
    # Final assessment
    print(f"\nğŸ¯ OPTIMIZATION STATUS:")
    
    if overall_success:
        print("ğŸ‰ PERFORMANCE OPTIMIZATION: SUCCESS!")
        print("ğŸš€ Ready for industry leadership validation")
        
        # Calculate projected performance
        current_speed = 45.0  # From Session 4 distributed training
        mixed_precision_boost = results['mixed_precision'].get('speedup', 1.0)
        projected_speed = current_speed * mixed_precision_boost
        
        print(f"\nğŸ“ˆ PERFORMANCE PROJECTION:")
        print(f"   Current (Distributed): {current_speed:.1f} steps/sec")
        print(f"   Mixed Precision Boost: {mixed_precision_boost:.2f}x")
        print(f"   Projected Performance: {projected_speed:.1f} steps/sec")
        
        if projected_speed >= 70:
            print("ğŸ† INDUSTRY LEADERSHIP TARGET: ACHIEVED!")
        elif projected_speed >= 60:
            print("âš¡ COMPETITIVE PERFORMANCE: ACHIEVED!")
        else:
            print("ğŸ”§ APPROACHING TARGET: Continue optimization")
    else:
        print("ğŸ”§ PERFORMANCE OPTIMIZATION: NEEDS WORK")
        print("âš ï¸ Address critical issues before proceeding")
    
    return results

if __name__ == "__main__":
    optimization_results = run_performance_optimization_validation()
    
    # Quick summary
    print(f"\nğŸ“Š RESULTS SUMMARY:")
    for component, result in optimization_results.items():
        status = result.get('status', 'unknown')
        icon = "âœ…" if status == 'success' else "âš ï¸" if status in ['partial', 'skipped'] else "âŒ"
        print(f"{icon} {component.upper()}: {status.upper()}")
    
    print(f"\nğŸ¯ Next Steps:")
    print("1. Deploy optimizations to distributed training system")
    print("2. Run full system benchmark validation")
    print("3. Prepare performance data for research publication")